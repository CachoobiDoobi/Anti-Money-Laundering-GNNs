{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'axes.facecolor': 'dimgrey', 'grid.color': 'lightgrey'})\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T21:51:03.514729600Z",
     "start_time": "2023-06-27T21:50:58.140293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "%run gcn_model.ipynb\n",
    "%run GAT_model.ipynb\n",
    "%run FeatureAggregationModel.ipynb\n",
    "%run LSTM_GNN.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T21:51:26.500720400Z",
     "start_time": "2023-06-27T21:51:26.300489200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "# class 1 is illicit, 2 is licit, unknown is unknown\n",
    "labels = pd.read_csv(\"data/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
    "edges = pd.read_csv(\"data/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
    "nodes = pd.read_csv(\"data/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T21:51:40.259092100Z",
     "start_time": "2023-06-27T21:51:27.219807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "indexes = labels.index[labels[\"class\"] != \"unknown\"].tolist()\n",
    "new_labels = labels.replace(\"unknown\", 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T21:51:40.331018Z",
     "start_time": "2023-06-27T21:51:40.263084500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 31\n",
      "val 5\n",
      "test 13\n"
     ]
    }
   ],
   "source": [
    "data, graph_info = time_step_split(nodes, edges, new_labels, device)\n",
    "for key in data:\n",
    "    print(key, len(data[key]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T21:52:16.987774Z",
     "start_time": "2023-06-27T21:51:40.335009400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[7880, 165], edge_index=[2, 9164], y=[7880]), Data(x=[4544, 165], edge_index=[2, 5241], y=[4544]), Data(x=[6621, 165], edge_index=[2, 8316], y=[6621]), Data(x=[5693, 165], edge_index=[2, 8180], y=[5693]), Data(x=[6803, 165], edge_index=[2, 8623], y=[6803]), Data(x=[4328, 165], edge_index=[2, 5242], y=[4328]), Data(x=[6048, 165], edge_index=[2, 7253], y=[6048]), Data(x=[4457, 165], edge_index=[2, 5186], y=[4457]), Data(x=[4996, 165], edge_index=[2, 5939], y=[4996]), Data(x=[6727, 165], edge_index=[2, 8588], y=[6727]), Data(x=[4296, 165], edge_index=[2, 4656], y=[4296]), Data(x=[2047, 165], edge_index=[2, 2213], y=[2047]), Data(x=[4528, 165], edge_index=[2, 4827], y=[4528]), Data(x=[2022, 165], edge_index=[2, 2078], y=[2022]), Data(x=[3639, 165], edge_index=[2, 3823], y=[3639]), Data(x=[2975, 165], edge_index=[2, 3120], y=[2975]), Data(x=[3385, 165], edge_index=[2, 3650], y=[3385]), Data(x=[1976, 165], edge_index=[2, 2115], y=[1976]), Data(x=[3506, 165], edge_index=[2, 3838], y=[3506]), Data(x=[4291, 165], edge_index=[2, 4755], y=[4291]), Data(x=[3537, 165], edge_index=[2, 3959], y=[3537]), Data(x=[5894, 165], edge_index=[2, 7014], y=[5894]), Data(x=[4165, 165], edge_index=[2, 4584], y=[4165]), Data(x=[4592, 165], edge_index=[2, 5124], y=[4592]), Data(x=[2314, 165], edge_index=[2, 2619], y=[2314]), Data(x=[2523, 165], edge_index=[2, 2690], y=[2523]), Data(x=[1089, 165], edge_index=[2, 1168], y=[1089]), Data(x=[1653, 165], edge_index=[2, 1717], y=[1653]), Data(x=[4275, 165], edge_index=[2, 4541], y=[4275]), Data(x=[2483, 165], edge_index=[2, 2561], y=[2483]), Data(x=[2816, 165], edge_index=[2, 3049], y=[2816])]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ClusterLoader, RandomNodeLoader, ImbalancedSampler\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m----> 4\u001B[0m sampler \u001B[38;5;241m=\u001B[39m \u001B[43mImbalancedSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# test_sampler = ImbalancedSampler(data, input_nodes=test_mask)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# train_loader = NeighborLoader(data,\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#                         batch_size=1024, num_neighbors=[20, 1],\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m#                               batch_size=1024, num_neighbors=[20, 1],\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m#                               sampler=test_sampler,input_nodes=test_mask)\u001B[39;00m\n\u001B[0;32m     13\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m], sampler\u001B[38;5;241m=\u001B[39msampler)\n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\torch_geometric\\loader\\imbalanced_sampler.py:90\u001B[0m, in \u001B[0;36mImbalancedSampler.__init__\u001B[1;34m(self, dataset, input_nodes, num_samples)\u001B[0m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     89\u001B[0m         y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(ys)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 90\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dataset) \u001B[38;5;241m==\u001B[39m y\u001B[38;5;241m.\u001B[39mnumel()\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m y\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mlong  \u001B[38;5;66;03m# Require classification.\u001B[39;00m\n\u001B[0;32m     94\u001B[0m num_samples \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;28;01mif\u001B[39;00m num_samples \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m num_samples\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import ClusterLoader, RandomNodeLoader, ImbalancedSampler\n",
    "print(data[\"train\"])\n",
    "sampler = ImbalancedSampler(data[\"train\"])\n",
    "train_loader = DataLoader(data[\"train\"], sampler=sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T21:56:52.791934100Z",
     "start_time": "2023-06-27T21:56:52.735793700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.766105    0.978105  0.969443    0.872105      0.968460\n",
      "recall      0.715185    0.984999  0.969443    0.850092      0.969443\n",
      "f1-score    0.732893    0.981477  0.969443    0.857185      0.968573\n",
      "support    98.709677  792.096774  0.969443  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.532961    0.983098  0.927905     0.758029      0.950288\n",
      "recall       0.858724    0.933248  0.927905     0.895986      0.927905\n",
      "f1-score     0.631892    0.957464  0.927905     0.794678      0.936148\n",
      "support    123.400000  942.200000  0.927905  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.247448    0.966387  0.896466     0.606917      0.927532\n",
      "recall      0.367032    0.921225  0.896466     0.644129      0.896466\n",
      "f1-score    0.284285    0.942567  0.896466     0.613426      0.908924\n",
      "support    66.769231  981.000000  0.896466  1047.769231   1047.769231, 0.8500916978954968, 0.8959859149009339, 0.6441286944845435]\n",
      "1\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.737208    0.977924  0.966676    0.857566      0.965785\n",
      "recall      0.707995    0.981636  0.966676    0.844816      0.966676\n",
      "f1-score    0.715601    0.979712  0.966676    0.847657      0.965885\n",
      "support    98.709677  792.096774  0.966676  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.507409    0.984970  0.921718     0.746189      0.948546\n",
      "recall       0.865600    0.924216  0.921718     0.894908      0.921718\n",
      "f1-score     0.616313    0.953539  0.921718     0.784926      0.931226\n",
      "support    123.400000  942.200000  0.921718  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.235135    0.967048   0.87734     0.601091      0.926550\n",
      "recall      0.425815    0.899638   0.87734     0.662726      0.877340\n",
      "f1-score    0.282184    0.931219   0.87734     0.606701      0.897389\n",
      "support    66.769231  981.000000   0.87734  1047.769231   1047.769231, 0.844815774846131, 0.8949080388605862, 0.6627264292696707]\n",
      "2\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.760246    0.979143  0.968672    0.869695      0.968043\n",
      "recall      0.723602    0.982969  0.968672    0.853286      0.968672\n",
      "f1-score    0.734040    0.980988  0.968672    0.857514      0.968008\n",
      "support    98.709677  792.096774  0.968672  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.526403    0.983818  0.927146     0.755111      0.950294\n",
      "recall       0.833542    0.931689  0.927146     0.882615      0.927146\n",
      "f1-score     0.623515    0.956966  0.927146     0.790240      0.935753\n",
      "support    123.400000  942.200000  0.927146  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.252087    0.967020  0.890653     0.609554      0.928013\n",
      "recall      0.393680    0.914213  0.890653     0.653947      0.890653\n",
      "f1-score    0.287312    0.939065  0.890653     0.613188      0.905439\n",
      "support    66.769231  981.000000  0.890653  1047.769231   1047.769231, 0.8532855314231118, 0.8826154881418983, 0.6539466929583246]\n",
      "3\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.765096    0.978749  0.969113    0.871923      0.968223\n",
      "recall      0.721177    0.983895  0.969113    0.852536      0.969113\n",
      "f1-score    0.735686    0.981264  0.969113    0.858475      0.968350\n",
      "support    98.709677  792.096774  0.969113  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.534550    0.982927  0.929688     0.758739      0.950962\n",
      "recall       0.854417    0.935810  0.929688     0.895113      0.929688\n",
      "f1-score     0.632288    0.958749  0.929688     0.795519      0.937546\n",
      "support    123.400000  942.200000  0.929688  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.258797    0.967077  0.898287     0.612937      0.929516\n",
      "recall      0.371377    0.923268  0.898287     0.647322      0.898287\n",
      "f1-score    0.292770    0.943891  0.898287     0.618330      0.910882\n",
      "support    66.769231  981.000000  0.898287  1047.769231   1047.769231, 0.8525359702759396, 0.8951134672556071, 0.6473224260146768]\n",
      "4\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.720907    0.977465  0.963249    0.849186      0.962900\n",
      "recall      0.712677    0.977613  0.963249    0.845145      0.963249\n",
      "f1-score    0.710975    0.977474  0.963249    0.844224      0.962750\n",
      "support    98.709677  792.096774  0.963249  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.514143    0.984999  0.923363     0.749571      0.949140\n",
      "recall       0.869179    0.926055  0.923363     0.897617      0.923363\n",
      "f1-score     0.620202    0.954495  0.923363     0.787348      0.932532\n",
      "support    123.400000  942.200000  0.923363  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.253059    0.968318  0.886691     0.610689      0.929648\n",
      "recall      0.426488    0.909183  0.886691     0.667835      0.886691\n",
      "f1-score    0.290784    0.936844  0.886691     0.613814      0.903748\n",
      "support    66.769231  981.000000  0.886691  1047.769231   1047.769231, 0.8451451273810949, 0.8976170874963355, 0.6678354042016318]\n",
      "5\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.748023    0.978505   0.96853    0.863264      0.967725\n",
      "recall      0.716971    0.983403   0.96853    0.850187      0.968530\n",
      "f1-score    0.726213    0.980877   0.96853    0.853545      0.967761\n",
      "support    98.709677  792.096774   0.96853  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.530387    0.983848  0.927819     0.757118      0.950061\n",
      "recall       0.869392    0.932172  0.927819     0.900782      0.927819\n",
      "f1-score     0.633881    0.957253  0.927819     0.795567      0.935816\n",
      "support    123.400000  942.200000  0.927819  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.244408    0.967583  0.886981     0.605996      0.928207\n",
      "recall      0.401730    0.910230  0.886981     0.655980      0.886981\n",
      "f1-score    0.290467    0.937128  0.886981     0.613798      0.903801\n",
      "support    66.769231  981.000000  0.886981  1047.769231   1047.769231, 0.8501869738698045, 0.9007818673501635, 0.655980279309715]\n",
      "6\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.757641    0.978371  0.969288    0.868006      0.968242\n",
      "recall      0.713795    0.984434  0.969288    0.849115      0.969288\n",
      "f1-score    0.729417    0.981338  0.969288    0.855378      0.968430\n",
      "support    98.709677  792.096774  0.969288  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.543587    0.982893  0.932146     0.763240      0.951310\n",
      "recall       0.842367    0.938217  0.932146     0.890292      0.932146\n",
      "f1-score     0.638248    0.959983  0.932146     0.799115      0.939206\n",
      "support    123.400000  942.200000  0.932146  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.289335    0.967500  0.906684     0.628418      0.932764\n",
      "recall      0.375786    0.932179  0.906684     0.653982      0.906684\n",
      "f1-score    0.309573    0.948859  0.906684     0.629216      0.917073\n",
      "support    66.769231  981.000000  0.906684  1047.769231   1047.769231, 0.8491145992686631, 0.8902917723404261, 0.6539822773089697]\n",
      "7\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.746187    0.977269   0.96761    0.861728      0.966663\n",
      "recall      0.706936    0.983536   0.96761    0.845236      0.967610\n",
      "f1-score    0.720456    0.980319   0.96761    0.850388      0.966745\n",
      "support    98.709677  792.096774   0.96761  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.521547    0.983882  0.925667     0.752715      0.949570\n",
      "recall       0.856615    0.929870  0.925667     0.893243      0.925667\n",
      "f1-score     0.624824    0.956056  0.925667     0.790440      0.934351\n",
      "support    123.400000  942.200000  0.925667  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.247659    0.966845  0.893854     0.607252      0.927907\n",
      "recall      0.374733    0.918205  0.893854     0.646469      0.893854\n",
      "f1-score    0.287706    0.941100  0.893854     0.614403      0.907621\n",
      "support    66.769231  981.000000  0.893854  1047.769231   1047.769231, 0.8452360816047738, 0.8932427359437801, 0.6464689437891505]\n",
      "8\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.757151    0.979196  0.969238    0.868173      0.968422\n",
      "recall      0.721498    0.983574  0.969238    0.852536      0.969238\n",
      "f1-score    0.732842    0.981323  0.969238    0.857082      0.968516\n",
      "support    98.709677  792.096774  0.969238  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.546241    0.983073  0.931916     0.764657      0.951657\n",
      "recall       0.864199    0.937743  0.931916     0.900971      0.931916\n",
      "f1-score     0.644210    0.959830  0.931916     0.802020      0.939137\n",
      "support    123.400000  942.200000  0.931916  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.259812    0.966978  0.900599     0.613395      0.929755\n",
      "recall      0.372294    0.925984  0.900599     0.649139      0.900599\n",
      "f1-score    0.295546    0.945330  0.900599     0.620438      0.912548\n",
      "support    66.769231  981.000000  0.900599  1047.769231   1047.769231, 0.8525359349370011, 0.9009710241621786, 0.6491392019612291]\n",
      "9\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.708918    0.976901  0.962927    0.842909      0.962387\n",
      "recall      0.703441    0.977872  0.962927    0.840656      0.962927\n",
      "f1-score    0.701796    0.977325  0.962927    0.839561      0.962372\n",
      "support    98.709677  792.096774  0.962927  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.516503    0.984581  0.924897     0.750542      0.949135\n",
      "recall       0.851866    0.928017  0.924897     0.889941      0.924897\n",
      "f1-score     0.622021    0.955375  0.924897     0.788698      0.933587\n",
      "support    123.400000  942.200000  0.924897  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.243082    0.966905  0.884528     0.604993      0.927749\n",
      "recall      0.394356    0.907967  0.884528     0.651161      0.884528\n",
      "f1-score    0.287589    0.935716  0.884528     0.611652      0.902553\n",
      "support    66.769231  981.000000  0.884528  1047.769231   1047.769231, 0.8406562404682054, 0.8899413149378791, 0.6511613821055325]\n"
     ]
    }
   ],
   "source": [
    "mega_results_gcn = []\n",
    "for n in range(10):\n",
    "    print(n)\n",
    "    GCN = GNN_Example(node_dim=data[\"train\"][0].x.shape[1], edge_dim=1, output_dim=2, hidden_dim=256, n_gnn_layers=3, K=2, dropout_rate=0.1).to(device)\n",
    "    lr = 1e-3\n",
    "    epochs = 100\n",
    "    # weights for classes\n",
    "    weight = torch.tensor([0.5, 0.5]).to(device)\n",
    "    optimizer = torch.optim.Adam(GCN.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.NLLLoss(weight)\n",
    "\n",
    "    best_model = None\n",
    "    best_test_loss = 1e10\n",
    "    best_result = None\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    best_valid_auc= 0\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        # train with random split\n",
    "        loss = train(GCN, data['train'], optimizer, loss_fn, device)\n",
    "        losses.append(loss)\n",
    "        result = test(GCN, data, device)\n",
    "        train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result\n",
    "        if val_auc > best_valid_auc:\n",
    "            best_valid_auc = val_auc\n",
    "            best_model = copy.deepcopy(GCN)\n",
    "            best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
    "        # if epoch % 10 == 0:\n",
    "        #     print('Epoch: {:02},'.format(epoch),\n",
    "        #           'Loss:{:.4f}'.format(loss),\n",
    "        #           'Train:\\n{}\\n'.format(train_acc),\n",
    "        #           'Train_auc_roc: {}'.format(train_auc),\n",
    "        #           '\\n\\n'\n",
    "        #           'Valid:\\n{}\\n'.format(val_acc),\n",
    "        #           'Val_auc_roc: {}'.format(val_auc),\n",
    "        #           '\\n\\n'\n",
    "        #           'Test:\\n{}\\n'.format(test_acc),\n",
    "        #           'Test_auc_roc: {}'.format(test_auc),\n",
    "        #           '\\n'\n",
    "        #           )\n",
    "    state = {\"net\":best_model.state_dict(), \"optimizer\":optimizer.state_dict()}\n",
    "    torch.save(state, \"gcn.pt\")\n",
    "    mega_results_gcn.append(best_result)\n",
    "    print(best_result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T22:24:57.646813900Z",
     "start_time": "2023-06-27T22:02:29.356435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with open(\"mega_results_gcn\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(mega_results_gcn, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T22:24:57.655661600Z",
     "start_time": "2023-06-27T22:24:57.648807200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.647941    0.952959  0.930031    0.800450      0.931263\n",
      "recall      0.551229    0.961270  0.930031    0.756249      0.930031\n",
      "f1-score    0.567994    0.956574  0.930031    0.762284      0.928436\n",
      "support    98.709677  792.096774  0.930031  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.360194    0.982729  0.852587     0.671461      0.928504\n",
      "recall       0.881021    0.843063  0.852587     0.862042      0.852587\n",
      "f1-score     0.492518    0.906967  0.852587     0.699742      0.877357\n",
      "support    123.400000  942.200000  0.852587  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.193617    0.970532  0.796739     0.582075      0.926731\n",
      "recall      0.504761    0.809792  0.796739     0.657276      0.796739\n",
      "f1-score    0.261865    0.879176  0.796739     0.570520      0.846340\n",
      "support    66.769231  981.000000  0.796739  1047.769231   1047.769231, 0.7562493489948336, 0.862041972239998, 0.6572764223174651]\n",
      "1\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.615336    0.960981   0.93259    0.788158      0.935758\n",
      "recall      0.604249    0.955654   0.93259    0.779951      0.932590\n",
      "f1-score    0.591668    0.957951   0.93259    0.774809      0.932797\n",
      "support    98.709677  792.096774   0.93259  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.348082    0.983950  0.846003     0.666016      0.928713\n",
      "recall       0.814121    0.836183  0.846003     0.825152      0.846003\n",
      "f1-score     0.472422    0.903214  0.846003     0.687818      0.873521\n",
      "support    123.400000  942.200000  0.846003  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.167199    0.966094  0.787031     0.566646      0.919521\n",
      "recall      0.469448    0.801321  0.787031     0.635384      0.787031\n",
      "f1-score    0.232932    0.872770  0.787031     0.552851      0.837642\n",
      "support    66.769231  981.000000  0.787031  1047.769231   1047.769231, 0.7799512053713114, 0.8251523261183398, 0.6353844063449322]\n",
      "2\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.690839    0.967372  0.942928    0.829105      0.945501\n",
      "recall      0.631605    0.962297  0.942928    0.796951      0.942928\n",
      "f1-score    0.629527    0.964455  0.942928    0.796991      0.942542\n",
      "support    98.709677  792.096774  0.942928  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.379512    0.987584  0.864353     0.683548      0.934522\n",
      "recall       0.870299    0.853365  0.864353     0.861832      0.864353\n",
      "f1-score     0.511144    0.914665  0.864353     0.712904      0.886913\n",
      "support    123.400000  942.200000  0.864353  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.194471    0.971918  0.808785     0.583194      0.927441\n",
      "recall      0.505587    0.820524  0.808785     0.663055      0.808785\n",
      "f1-score    0.266612    0.886923  0.808785     0.576767      0.854036\n",
      "support    66.769231  981.000000  0.808785  1047.769231   1047.769231, 0.7969512656529306, 0.8618319158868081, 0.6630553580670168]\n",
      "3\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.623876    0.967885  0.937674    0.795881      0.941724\n",
      "recall      0.640380    0.954914  0.937674    0.797647      0.937674\n",
      "f1-score    0.615405    0.961030  0.937674    0.788218      0.938293\n",
      "support    98.709677  792.096774  0.937674  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.355150    0.989717  0.848832     0.672434      0.933253\n",
      "recall       0.856211    0.834025  0.848832     0.845118      0.848832\n",
      "f1-score     0.487016    0.903846  0.848832     0.695431      0.875324\n",
      "support    123.400000  942.200000  0.848832  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.181373    0.969203  0.802476     0.575288      0.923556\n",
      "recall      0.463097    0.815648  0.802476     0.639372      0.802476\n",
      "f1-score    0.248705    0.882693  0.802476     0.565699      0.848455\n",
      "support    66.769231  981.000000  0.802476  1047.769231   1047.769231, 0.7976473039318795, 0.8451179449574937, 0.6393724705300481]\n",
      "4\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.692285    0.966789  0.947804    0.829537      0.948701\n",
      "recall      0.636795    0.969175  0.947804    0.802985      0.947804\n",
      "f1-score    0.640759    0.967733  0.947804    0.804246      0.947038\n",
      "support    98.709677  792.096774  0.947804  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.420560    0.985304  0.889269     0.702932      0.938537\n",
      "recall       0.867072    0.885051  0.889269     0.876061      0.889269\n",
      "f1-score     0.546533    0.932182  0.889269     0.739357      0.905852\n",
      "support    123.400000  942.200000  0.889269  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.232539    0.969358  0.860992     0.600948      0.929435\n",
      "recall      0.413586    0.881125  0.860992     0.647356      0.860992\n",
      "f1-score    0.289896    0.920859  0.860992     0.605378      0.888548\n",
      "support    66.769231  981.000000  0.860992  1047.769231   1047.769231, 0.8029848998019132, 0.8760613781808946, 0.6473558374305328]\n",
      "5\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.652919    0.974245  0.945352    0.813582      0.949326\n",
      "recall      0.688477    0.958036  0.945352    0.823257      0.945352\n",
      "f1-score    0.655646    0.965810  0.945352    0.810728      0.946137\n",
      "support    98.709677  792.096774  0.945352  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.387863    0.989609  0.867344     0.688736      0.936601\n",
      "recall       0.887028    0.854741  0.867344     0.870885      0.867344\n",
      "f1-score     0.521287    0.915953  0.867344     0.718620      0.889038\n",
      "support    123.400000  942.200000  0.867344  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.200025    0.971277  0.821503     0.585651      0.927349\n",
      "recall      0.469758    0.835115  0.821503     0.652437      0.821503\n",
      "f1-score    0.269020    0.895267  0.821503     0.582143      0.862141\n",
      "support    66.769231  981.000000  0.821503  1047.769231   1047.769231, 0.8232565314710604, 0.8708845558746295, 0.652436555605233]\n",
      "6\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.646600    0.965225  0.941705    0.805912      0.943295\n",
      "recall      0.614886    0.962995  0.941705    0.788941      0.941705\n",
      "f1-score    0.613097    0.963818  0.941705    0.788457      0.941280\n",
      "support    98.709677  792.096774  0.941705  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.388478    0.987056  0.870784     0.687767      0.935373\n",
      "recall       0.863069    0.861165  0.870784     0.862117      0.870784\n",
      "f1-score     0.518717    0.918990  0.870784     0.718854      0.891635\n",
      "support    123.400000  942.200000  0.870784  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.192093    0.969447  0.822952     0.580770      0.924903\n",
      "recall      0.482339    0.838488  0.822952     0.660413      0.822952\n",
      "f1-score    0.257387    0.896033  0.822952     0.576710      0.861757\n",
      "support    66.769231  981.000000  0.822952  1047.769231   1047.769231, 0.7889405893394652, 0.8621166267748729, 0.6604132261415198]\n",
      "7\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.616188    0.968826  0.937311    0.792507      0.941941\n",
      "recall      0.647838    0.953489  0.937311    0.800663      0.937311\n",
      "f1-score    0.617778    0.960822  0.937311    0.789300      0.938402\n",
      "support    98.709677  792.096774  0.937311  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.366417    0.989142  0.856848     0.677780      0.934171\n",
      "recall       0.857521    0.843825  0.856848     0.850673      0.856848\n",
      "f1-score     0.497261    0.909454  0.856848     0.703358      0.881360\n",
      "support    123.400000  942.200000  0.856848  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.183586    0.969183  0.814457     0.576384      0.923748\n",
      "recall      0.492605    0.828796  0.814457     0.660700      0.814457\n",
      "f1-score    0.250518    0.890502  0.814457     0.570510      0.856017\n",
      "support    66.769231  981.000000  0.814457  1047.769231   1047.769231, 0.8006631777917471, 0.8506732739958979, 0.6607003324078669]\n",
      "8\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.595736    0.972953  0.935145    0.784344      0.942576\n",
      "recall      0.670608    0.946594  0.935145    0.808601      0.935145\n",
      "f1-score    0.617396    0.959262  0.935145    0.788329      0.937176\n",
      "support    98.709677  792.096774  0.935145  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.350428    0.989717  0.845743     0.670073      0.932547\n",
      "recall       0.866507    0.829698  0.845743     0.848103      0.845743\n",
      "f1-score     0.483985    0.901018  0.845743     0.692502      0.872593\n",
      "support    123.400000  942.200000  0.845743  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.183655    0.969987  0.800479     0.576821      0.924382\n",
      "recall      0.484471    0.812535  0.800479     0.648503      0.800479\n",
      "f1-score    0.254574    0.880992  0.800479     0.567783      0.847203\n",
      "support    66.769231  981.000000  0.800479  1047.769231   1047.769231, 0.8086012118400512, 0.8481027257027851, 0.6485032132388497]\n",
      "9\n",
      "[                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.650517    0.952492  0.930184    0.801504      0.931535\n",
      "recall      0.546528    0.962530  0.930184    0.754529      0.930184\n",
      "f1-score    0.565161    0.956916  0.930184    0.761038      0.928345\n",
      "support    98.709677  792.096774  0.930184  890.806452    890.806452,                     0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.351846    0.987697  0.849305     0.669772      0.931888\n",
      "recall       0.871771    0.835716  0.849305     0.853743      0.849305\n",
      "f1-score     0.485005    0.904389  0.849305     0.694697      0.875526\n",
      "support    123.400000  942.200000  0.849305  1065.600000   1065.600000,                    0           1  accuracy    macro avg  weighted avg\n",
      "precision   0.186515    0.970881  0.792397     0.578698      0.925889\n",
      "recall      0.488567    0.803741  0.792397     0.646154      0.792397\n",
      "f1-score    0.257759    0.875929  0.792397     0.566844      0.842920\n",
      "support    66.769231  981.000000  0.792397  1047.769231   1047.769231, 0.7545293784080537, 0.853743378546648, 0.6461543399268243]\n"
     ]
    }
   ],
   "source": [
    "%run GAT_model.ipynb\n",
    "mega_results_gat = []\n",
    "for n in range(10):\n",
    "    print(n)\n",
    "    GAT = GraphAttentionNetwork(node_dim=data[\"train\"][0].x.shape[1], output_dim=2, hidden_dim=256, n_gnn_layers=1, heads=2, dropout_rate=0.5).to(device)\n",
    "    lr = 1e-3\n",
    "    epochs = 100\n",
    "    # weights for classes\n",
    "    weight = torch.tensor([0.5, 0.5]).to(device)\n",
    "    optimizer = torch.optim.Adam(GAT.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.NLLLoss(weight)\n",
    "\n",
    "    best_model = None\n",
    "    best_valid_auc = 0\n",
    "    best_result = None\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        # train with random split\n",
    "        loss = train(GAT, data['train'], optimizer, loss_fn, device)\n",
    "        losses.append(loss)\n",
    "        result = test(GAT, data, device)\n",
    "        train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result\n",
    "        if val_auc > best_valid_auc:\n",
    "            best_valid_auc = val_auc\n",
    "            best_model = copy.deepcopy(GAT)\n",
    "            best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
    "    state = {\"net\":best_model.state_dict(), \"optimizer\":optimizer.state_dict()}\n",
    "    torch.save(state, \"gat.pt\")\n",
    "    mega_results_gat.append(best_result)\n",
    "    print(best_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T22:50:10.293138Z",
     "start_time": "2023-06-27T22:27:01.209695700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "with open(\"mega_results_gat\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(mega_results_gat, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T22:50:10.303624100Z",
     "start_time": "2023-06-27T22:50:10.298124100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "mega_results_sfa = []\n",
    "for n in range(10):\n",
    "    print(n)\n",
    "    SFA = SpatialFeatureAggregator(node_dim=data[\"train\"][0].x.shape[1], edge_dim=1, output_dim=2, hidden_dim=256, n_gnn_layers=3, K=2, dropout_rate=0.1).to(device)\n",
    "    lr = 1e-3\n",
    "    epochs = 100\n",
    "    # weights for classes\n",
    "    weight = torch.tensor([0.5, 0.5]).to(device)\n",
    "    optimizer = torch.optim.Adam(SFA.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.NLLLoss(weight)\n",
    "\n",
    "    best_model = None\n",
    "    best_valid_auc = 0\n",
    "    best_result = None\n",
    "    losses = []\n",
    "    best_test_loss = 0\n",
    "\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        # train with random split\n",
    "        loss = train(SFA, data['train'], optimizer, loss_fn, device)\n",
    "        losses.append(loss)\n",
    "        result = test(SFA, data, device)\n",
    "        train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result\n",
    "        if val_auc > best_valid_auc:\n",
    "            best_valid_auc = val_auc\n",
    "            best_model = copy.deepcopy(SFA)\n",
    "            best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
    "    state = {\"net\":best_model.state_dict(), \"optimizer\":optimizer.state_dict()}\n",
    "    torch.save(state, \"SFA.pt\")\n",
    "    mega_results_sfa.append(best_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T23:13:41.518781600Z",
     "start_time": "2023-06-27T22:50:10.309608600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "with open(\"mega_results_sfa\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(mega_results_sfa, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T23:13:41.525338800Z",
     "start_time": "2023-06-27T23:13:41.521771100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "D:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "mega_results_tb =[]\n",
    "for n in range(10):\n",
    "    TB = TemporalBoy(node_dim=data[\"train\"][0].x.shape[1], edge_dim=1, output_dim=2, hidden_dim=256, n_gnn_layers=3, K=2, dropout_rate=0.1).to(device)\n",
    "    lr = 1e-3\n",
    "    epochs = 100\n",
    "    # weights for classes\n",
    "    weight = torch.tensor([0.5, 0.5]).to(device)\n",
    "    optimizer = torch.optim.Adam(TB.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.NLLLoss(weight)\n",
    "\n",
    "    best_model = None\n",
    "    best_valid_auc = 0\n",
    "    best_result = None\n",
    "    losses = []\n",
    "    best_test_loss = 0\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        # train with random split\n",
    "        loss = train(TB, data['train'], optimizer, loss_fn, device)\n",
    "        losses.append(loss)\n",
    "        result = test(TB, data, device)\n",
    "        train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result\n",
    "        if val_auc > best_valid_auc:\n",
    "            best_valid_auc = val_auc\n",
    "            best_model = copy.deepcopy(TB)\n",
    "            best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(\"Epoch: \", epoch)\n",
    "        #     for item, amount in result.items():\n",
    "        #             print(\"{} ({})\".format(item, amount))\n",
    "        #     print(\"############################\")\n",
    "    state = {\"net\":best_model.state_dict(), \"optimizer\":optimizer.state_dict()}\n",
    "    torch.save(state, \"TB.pt\")\n",
    "    mega_results_tb.append(best_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T03:11:54.170679300Z",
     "start_time": "2023-06-27T23:13:41.532322800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open(\"mega_results_tb\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(mega_results_tb, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T03:11:54.179052Z",
     "start_time": "2023-06-28T03:11:54.172674100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_std_results(results):\n",
    "    f1_0 = []\n",
    "    f1_1 = []\n",
    "    f1_avg = []\n",
    "    for result in results:\n",
    "        f1_0.append(result[2][\"0\"][\"f1-score\"])\n",
    "        f1_1.append(result[2][\"1\"][\"f1-score\"])\n",
    "        f1_avg.append(result[2][\"macro avg\"][\"f1-score\"])\n",
    "    return (np.mean(f1_0), np.std(f1_0)),(np.mean(f1_1),np.std(f1_1)),(np.mean(f1_avg),np.std(f1_avg)),"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T08:24:42.719667600Z",
     "start_time": "2023-06-28T08:24:42.692590800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "((0.29082152955234253, 0.007263991102777121),\n (0.9401719702666735, 0.004940283751679395),\n (0.6154967499095081, 0.005738649192763499))"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_results(mega_results_gcn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T08:25:10.077395300Z",
     "start_time": "2023-06-28T08:25:10.052364900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "((0.25892677337408615, 0.014150142688408661),\n (0.8881142419917909, 0.013180160608831802),\n (0.5735205076829384, 0.013015052939925761))"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_results(mega_results_gat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T08:24:43.530174300Z",
     "start_time": "2023-06-28T08:24:43.500310400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "((0.30332387876084965, 0.006462005093711699),\n (0.9448299412616554, 0.004954678576242759),\n (0.6240769100112525, 0.005096571747988077))"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_results(mega_results_sfa)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T08:25:15.305514Z",
     "start_time": "2023-06-28T08:25:15.290653200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "((0.27380298791921376, 0.010335485580295128),\n (0.944866063637037, 0.005261707735817781),\n (0.6093345257781255, 0.007520315943807319))"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_results(mega_results_tb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T08:25:15.627409200Z",
     "start_time": "2023-06-28T08:25:15.603753200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
