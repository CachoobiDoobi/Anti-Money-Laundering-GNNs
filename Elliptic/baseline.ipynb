{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:13.067794382Z",
     "start_time": "2023-06-28T18:36:13.032434767Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'axes.facecolor': 'dimgrey', 'grid.color': 'lightgrey'})\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tqdm.notebook import tqdm\n",
    "from pygsp import graphs\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:13.223173664Z",
     "start_time": "2023-06-28T18:36:13.181479012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:13.375456279Z",
     "start_time": "2023-06-28T18:36:13.333742631Z"
    }
   },
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:17.810910433Z",
     "start_time": "2023-06-28T18:36:13.502780694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# class 1 is illicit, 2 is licit, unknown is unknown\n",
    "labels = pd.read_csv(\"data/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
    "edges = pd.read_csv(\"data/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
    "nodes = pd.read_csv(\"data/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header=None)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:17.846752720Z",
     "start_time": "2023-06-28T18:36:17.811363924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((203769, 167), (203769, 2), (234355, 2))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = labels.index.tolist()\n",
    "labels_new = labels\n",
    "labels_new = labels_new.replace('unknown', 3)\n",
    "nodes_new =  nodes\n",
    "edges_new = edges.loc[edges[\"txId1\"].isin(labels_new[\"txId\"])].loc[edges[\"txId2\"].isin(labels_new[\"txId\"])]\n",
    "nodes_new.shape, labels_new.shape, edges_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:32.920958313Z",
     "start_time": "2023-06-28T18:36:17.926908359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 31\n",
      "val 5\n",
      "test 13\n"
     ]
    }
   ],
   "source": [
    "data, graph_info = time_step_split(nodes_new, edges_new, labels_new, device)\n",
    "for key in data:\n",
    "    print(key, len(data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:40.968764547Z",
     "start_time": "2023-06-28T18:36:32.991726505Z"
    }
   },
   "outputs": [],
   "source": [
    "data, graph_info = create_graph(nodes_new, edges_new, labels_new, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:36:41.112161677Z",
     "start_time": "2023-06-28T18:36:40.970934862Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate test and train masks\n",
    "train_p = 0.8\n",
    "def generateMasks(train_p=train_p):\n",
    "    # indeces of the illicit and licit transaction nodes\n",
    "    illicit_idx = (data.y == 0).nonzero(as_tuple=True)[0]\n",
    "    # Generate random permutation of indices\n",
    "    illicit_train, illicit_test = torch.utils.data.random_split(illicit_idx, lengths=[train_p, (1-train_p)])\n",
    "\n",
    "    # the same for the licit nodes\n",
    "    licit_idx   = (data.y == 1).nonzero(as_tuple=True)[0]\n",
    "    licit_train, licit_test = torch.utils.data.random_split(licit_idx, lengths=[train_p, (1-train_p)])\n",
    "    # obtain the training and test \"masks\", i.e. indices for the train and test sets\n",
    "    train_mask = torch.cat((torch.tensor(illicit_train), torch.tensor(licit_train)))\n",
    "    test_mask  = torch.cat((torch.tensor(illicit_test), torch.tensor(licit_test)))\n",
    "    return train_mask, test_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T18:41:14.938774685Z",
     "start_time": "2023-06-28T18:39:32.827508429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       807\n",
      "           1       1.00      0.99      0.99      8504\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.97      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       809\n",
      "           1       1.00      0.99      0.99      8502\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       802\n",
      "           1       1.00      0.99      0.99      8509\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       783\n",
      "           1       1.00      0.99      0.99      8528\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.93      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       800\n",
      "           1       1.00      0.99      0.99      8511\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       808\n",
      "           1       1.00      0.99      0.99      8503\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       805\n",
      "           1       1.00      0.99      0.99      8506\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       801\n",
      "           1       1.00      0.99      0.99      8510\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       800\n",
      "           1       1.00      0.99      0.99      8511\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.94      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       788\n",
      "           1       1.00      0.99      0.99      8523\n",
      "\n",
      "    accuracy                           0.99      9311\n",
      "   macro avg       0.93      0.99      0.96      9311\n",
      "weighted avg       0.99      0.99      0.99      9311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # apply the training and test masks\n",
    "    train_mask, test_mask = generateMasks()\n",
    "    train_emb = data.x[train_mask]\n",
    "    train_y   = data.y[train_mask]\n",
    "\n",
    "    test_emb  = data.x[test_mask]\n",
    "    test_y    = data.y[test_mask]\n",
    "\n",
    "    # Create Decision Tree classifer object\n",
    "    clf = RandomForestClassifier()\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(train_emb, train_y)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(test_emb)\n",
    "\n",
    "    print(classification_report(y_pred, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T16:33:30.008582282Z",
     "start_time": "2023-06-10T16:33:29.968567953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define your Node2Vec model here\n",
    "def defineNode2VecModel(edge_index):\n",
    "    n2v = Node2Vec(edge_index=edge_index, embedding_dim=3, walk_length=20, context_size=10,\n",
    "                   walks_per_node=10, num_negative_samples=1,\n",
    "                   p=1, q=1, sparse=False)\n",
    "    return n2v\n",
    "# print(type(torch.tensor(data.edge_index)))\n",
    "n2v = defineNode2VecModel(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T16:33:30.027446087Z",
     "start_time": "2023-06-10T16:33:29.988805425Z"
    }
   },
   "outputs": [],
   "source": [
    "# training and test loops\n",
    "# define the training function for the Node2Vec model here\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "#########################################################################\n",
    "\n",
    "#########################################################################\n",
    "#define the test function for the Node2Vec model here\n",
    "@torch.no_grad()\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    z = model()\n",
    "    acc = model.test(z[train_mask], data.y[train_mask],\n",
    "                   z[test_mask], data.y[test_mask],\n",
    "                   max_iter=150)\n",
    "    return acc\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T16:44:48.901499305Z",
     "start_time": "2023-06-10T16:33:29.992201331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b33d459ed4c4cf88b5172110d7e4f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.0179, Acc: 0.9025\n",
      "Epoch: 001, Loss: 0.8527, Acc: 0.9025\n",
      "Epoch: 002, Loss: 0.8294, Acc: 0.9025\n",
      "Epoch: 003, Loss: 0.8249, Acc: 0.9025\n",
      "Epoch: 004, Loss: 0.8236, Acc: 0.9025\n",
      "Epoch: 005, Loss: 0.8230, Acc: 0.9025\n",
      "Epoch: 006, Loss: 0.8226, Acc: 0.9025\n",
      "Epoch: 007, Loss: 0.8223, Acc: 0.9025\n",
      "Epoch: 008, Loss: 0.8218, Acc: 0.9025\n",
      "Epoch: 009, Loss: 0.8216, Acc: 0.9025\n",
      "Epoch: 010, Loss: 0.8215, Acc: 0.9025\n",
      "Epoch: 011, Loss: 0.8213, Acc: 0.9025\n",
      "Epoch: 012, Loss: 0.8210, Acc: 0.9025\n",
      "Epoch: 013, Loss: 0.8210, Acc: 0.9025\n",
      "Epoch: 014, Loss: 0.8209, Acc: 0.9025\n",
      "Epoch: 015, Loss: 0.8208, Acc: 0.9025\n",
      "Epoch: 016, Loss: 0.8208, Acc: 0.9025\n",
      "Epoch: 017, Loss: 0.8206, Acc: 0.9025\n",
      "Epoch: 018, Loss: 0.8205, Acc: 0.9025\n",
      "Epoch: 019, Loss: 0.8204, Acc: 0.9025\n",
      "Epoch: 020, Loss: 0.8203, Acc: 0.9025\n",
      "Epoch: 021, Loss: 0.8202, Acc: 0.9025\n",
      "Epoch: 022, Loss: 0.8200, Acc: 0.9025\n",
      "Epoch: 023, Loss: 0.8200, Acc: 0.9025\n",
      "Epoch: 024, Loss: 0.8198, Acc: 0.9025\n",
      "Epoch: 025, Loss: 0.8198, Acc: 0.9025\n",
      "Epoch: 026, Loss: 0.8194, Acc: 0.9025\n",
      "Epoch: 027, Loss: 0.8191, Acc: 0.9025\n",
      "Epoch: 028, Loss: 0.8189, Acc: 0.9025\n",
      "Epoch: 029, Loss: 0.8187, Acc: 0.9025\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# train your Node2Vec model\n",
    "train_epochs = 30\n",
    "# Define a loader here\n",
    "loader = n2v.loader(batch_size=128, shuffle=True)\n",
    "# define an optimizer here\n",
    "optimizer = torch.optim.Adam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "for epoch in tqdm(range(train_epochs)):\n",
    "    loss = train(n2v, loader, optimizer)\n",
    "    acc = test(n2v)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}')\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:51.455843678Z",
     "start_time": "2023-06-28T17:36:51.412917196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203769\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# produce embedding using the trained model\n",
    "n2v.eval()\n",
    "emb = n2v(torch.arange(data.num_nodes))\n",
    "# visualize the features here\n",
    "emb = emb.detach().numpy()\n",
    "print(len(emb))\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:52.050875097Z",
     "start_time": "2023-06-28T17:36:52.042113474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2813215   0.2716136   0.31932402]\n",
      " [ 0.5437697   0.18883954 -0.37878326]\n",
      " [-1.1976874  -1.0985088   0.81091505]\n",
      " ...\n",
      " [ 0.54584605  0.29015455 -0.5372091 ]\n",
      " [-0.10954577  0.32879618 -0.03851182]\n",
      " [-0.03797907 -0.42184383 -0.2959392 ]]\n",
      "tensor([0, 0, 0,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# apply the training and test masks\n",
    "train_emb = emb[train_mask]\n",
    "train_y   = data.y[train_mask]\n",
    "\n",
    "test_emb  = emb[test_mask]\n",
    "test_y    = data.y[test_mask]\n",
    "\n",
    "print(train_emb)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:52.719512021Z",
     "start_time": "2023-06-28T17:36:52.711207451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now train the DT classifier\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:53.298591940Z",
     "start_time": "2023-06-28T17:36:53.118708341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(train_emb, train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:53.826666649Z",
     "start_time": "2023-06-28T17:36:53.822343862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8264418429814199\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:03:28.163269265Z",
     "start_time": "2023-06-10T17:03:28.142464677Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(n2v, 'BaselineModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
